{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43650d53-7aba-43c9-898f-60a7726481c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import fetch_dataset\n",
    "from src.model_backbone import DinoBackbone\n",
    "from src.model_head import LiteFlowHead\n",
    "from src.loss import sequence_loss\n",
    "import config.config as cfg\n",
    "from src.common import tensor_to_image\n",
    "from src.utils import flow_to_image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import json\n",
    "import sys\n",
    "import copy\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee63c50f-e5c1-4798-bfe6-a4333f0ff37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device: \", device)\n",
    "\n",
    "################ LOAD ALL THE PARAMETERS #############################\n",
    "# DATASET PARAMETERS\n",
    "DATASET_NAME = cfg.DATASET_NAME\n",
    "DATASET_LOCATIONS = cfg.DATASET_LOCATIONS\n",
    "IMG_SIZE = cfg.IMG_SIZE\n",
    "PATCH_SIZE = cfg.PATCH_SIZE\n",
    "PROB_AUGMENT_TRAINING = cfg.PROB_AUGMENT_TRAINING\n",
    "PROB_AUGMENT_VALID = cfg.PROB_AUGMENT_VALID\n",
    "IMG_MEAN = cfg.IMG_MEAN\n",
    "IMG_STD = cfg.IMG_STD\n",
    "\n",
    "# MODEL PARAMETERS\n",
    "DINOV3_DIR = cfg.DINOV3_DIR\n",
    "DINO_MODEL = cfg.DINO_MODEL\n",
    "DINO_WEIGHTS = cfg.DINO_WEIGHTS\n",
    "MODEL_TO_NUM_LAYERS = cfg.MODEL_TO_NUM_LAYERS\n",
    "MODEL_TO_EMBED_DIM = cfg.MODEL_TO_EMBED_DIM\n",
    "\n",
    "# TRAINING PARAMETERS\n",
    "BATCH_SIZE = cfg.BATCH_SIZE\n",
    "\n",
    "LEARNING_RATE = cfg.LEARNING_RATE\n",
    "WEIGHT_DECAY = cfg.WEIGHT_DECAY\n",
    "NUM_EPOCHS = cfg.NUM_EPOCHS\n",
    "NUM_SAMPLES_PLOT = cfg.NUM_SAMPLES_PLOT\n",
    "\n",
    "LOAD_MODEL = cfg.LOAD_MODEL\n",
    "SAVE_MODEL = cfg.SAVE_MODEL\n",
    "MODEL_PATH_TRAIN_LOAD = cfg.MODEL_PATH_TRAIN_LOAD\n",
    "RESULTS_PATH = cfg.RESULTS_PATH\n",
    "\n",
    "train_set = fetch_dataset(DATASET_NAME, DATASET_LOCATIONS, \"train\", IMG_SIZE, IMG_MEAN, IMG_STD, PROB_AUGMENT_TRAINING)\n",
    "train_dataloader = DataLoader(train_set, batch_size = BATCH_SIZE, num_workers=8, shuffle=True)\n",
    "\n",
    "val_set = fetch_dataset(DATASET_NAME, DATASET_LOCATIONS, \"val\", IMG_SIZE, IMG_MEAN, IMG_STD, PROB_AUGMENT_VALID)\n",
    "val_dataloader = DataLoader(val_set, batch_size = BATCH_SIZE, num_workers=8, shuffle=True)\n",
    "\n",
    "dino_model = torch.hub.load(\n",
    "        repo_or_dir=DINOV3_DIR,\n",
    "        model=DINO_MODEL,\n",
    "        source=\"local\",\n",
    "        weights=DINO_WEIGHTS\n",
    ")\n",
    "n_layers_dino = MODEL_TO_NUM_LAYERS[DINO_MODEL]\n",
    "embed_dim = MODEL_TO_EMBED_DIM[DINO_MODEL]\n",
    "\n",
    "dino_backbone = DinoBackbone(dino_model, n_layers_dino).to(device)\n",
    "\n",
    "#model_head = Dinov3FlowHead(img_size=IMG_SIZE, in_ch=embed_dim).to(device)\n",
    "model_head = LiteFlowHead(out_size=IMG_SIZE, \n",
    "                            in_channels = 384,\n",
    "                            proj_channels = 256,\n",
    "                            radius = 4,\n",
    "                            fusion_channels = 448,\n",
    "                            fusion_layers = 3, \n",
    "                            refinement_layers = 2).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model_head.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Load model\n",
    "if LOAD_MODEL:\n",
    "    model_head.load_state_dict(torch.load(MODEL_PATH_TRAIN_LOAD))\n",
    "    print(\"Model successfully loaded!\")\n",
    "\n",
    "# Freeze parameters\n",
    "for p in dino_backbone.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "n_params = sum([p.numel() for p in dino_backbone.parameters()]) + sum([p.numel() for p in model_head.parameters()])\n",
    "print(\"Total number of parameters: \", n_params)\n",
    "n_trainable_params = sum([p.numel() for p in dino_backbone.parameters() if p.requires_grad]) + sum([p.numel() for p in model_head.parameters() if p.requires_grad])\n",
    "print(\"Total number of trainable parameters: \", n_trainable_params)\n",
    "n_params_backbone = sum([p.numel() for p in dino_backbone.parameters()])\n",
    "print(\"Number parameters backbone: \", n_params_backbone)\n",
    "\n",
    "if SAVE_MODEL:\n",
    "    current_date = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    folder_path = f\"{RESULTS_PATH}/{current_date}\"\n",
    "    \n",
    "    json_params = { \n",
    "        \"DATASET_NAME\": DATASET_NAME,\n",
    "        \"IMG_SIZE\" : IMG_SIZE, \n",
    "        \"PATCH_SIZE\" : PATCH_SIZE, \n",
    "        \"PROB_AUGMENT_TRAINING\": PROB_AUGMENT_TRAINING,\n",
    "        \"PROB_AUGMENT_VALID\": PROB_AUGMENT_VALID,\n",
    "        \"DINO_MODEL\": DINO_MODEL,\n",
    "        \"LEARNING_RATE\" : LEARNING_RATE,\n",
    "        \"LOAD_MODEL\" : LOAD_MODEL,\n",
    "        \"MODEL_PATH_TRAIN_LOAD\" : MODEL_PATH_TRAIN_LOAD,\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef2a77-dbda-4ee5-86ee-d9bdaff26d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DINO backbone always in eval mode\n",
    "dino_backbone.eval()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    ##################### TRAIN #######################\n",
    "    model_head.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (im1, im2, flow_gt, valid) in enumerate(tqdm(train_dataloader)):\n",
    "        im1 = im1.to(device, dtype=torch.float)\n",
    "        im2 = im2.to(device, dtype=torch.float)\n",
    "        flow_gt = flow_gt.to(device)\n",
    "        valid = valid.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        feat1 = dino_backbone(im1)\n",
    "        feat2 = dino_backbone(im2)\n",
    "        flow_pred = model_head(feat1, feat2)\n",
    "\n",
    "        # Check if flow_pred has NaNs\n",
    "        if torch.isnan(flow_pred).any():\n",
    "            print(\"flow_pred contains NaN values in batch_idx: \", batch_idx)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss, metrics = sequence_loss(flow_pred, flow_gt, valid)\n",
    "\n",
    "        # Check if loss is NaN\n",
    "        if torch.isnan(loss):\n",
    "            print(\"loss is NaN in batch_idx:\", batch_idx)\n",
    "            print(\"flow_pred min/max:\", flow_pred.min().item(), flow_pred.max().item())\n",
    "            print(\"flow_gt min/max:\", flow_gt.min().item(), flow_gt.max().item())\n",
    "            print(\"valid sum:\", valid.sum().item())\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping and Optimize\n",
    "        # clip all gradients to max norm 5.0\n",
    "        torch.nn.utils.clip_grad_norm_(model_head.parameters(), max_norm=5.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Show error\n",
    "        if (batch_idx % 250 == 0 and batch_idx > 0):\n",
    "            print(f\"Epoch {epoch+1}, batch {batch_idx}, Loss: {train_loss/(batch_idx+1)}\")\n",
    "\n",
    "        # Plot\n",
    "        if (batch_idx % 500 == 0 and batch_idx > 0):\n",
    "            with torch.no_grad():\n",
    "                for i in range(min(NUM_SAMPLES_PLOT, BATCH_SIZE)):\n",
    "                    im1_plot = tensor_to_image(im1[i], IMG_MEAN, IMG_STD)\n",
    "                    im2_plot = tensor_to_image(im2[i], IMG_MEAN, IMG_STD)\n",
    "                    flow_gt_plot = flow_to_image(flow_gt[i].permute(1,2,0).cpu().numpy())\n",
    "                    flow_pred_plot = flow_to_image(flow_pred[i].permute(1,2,0).cpu().numpy())\n",
    "                    # Put your images in a list\n",
    "                    images = [im1_plot, im2_plot, flow_gt_plot, flow_pred_plot]\n",
    "                    titles = [\"Image 1\", \"Image 2\", \"Flow GT\", \"Flow Pred\"]\n",
    "                    \n",
    "                    fig, axes = plt.subplots(1, 4, figsize=(16, 4))  # 1 row, 4 columns\n",
    "                    \n",
    "                    for ax, img, title in zip(axes, images, titles):\n",
    "                        ax.imshow(img)\n",
    "                        ax.set_title(title)\n",
    "                        ax.axis(\"off\")\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "    train_loss /= float(batch_idx+1)\n",
    "\n",
    "    ##################### VALIDATION #######################\n",
    "    model_head.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (im1, im2, flow_gt, valid) in enumerate(tqdm(val_dataloader)):\n",
    "            im1 = im1.to(device, dtype=torch.float)\n",
    "            im2 = im2.to(device, dtype=torch.float)\n",
    "            flow_gt = flow_gt.to(device)\n",
    "            valid = valid.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            feat1 = dino_backbone(im1)\n",
    "            feat2 = dino_backbone(im2)\n",
    "            flow_pred = model_head(feat1, feat2)\n",
    "    \n",
    "            # Calculate loss\n",
    "            loss, metrics = sequence_loss(flow_pred, flow_gt, valid)\n",
    "            \n",
    "            # Total loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Plot\n",
    "            if (batch_idx==0):\n",
    "                for i in range(min(NUM_SAMPLES_PLOT, BATCH_SIZE)):\n",
    "                    im1_plot = tensor_to_image(im1[i], IMG_MEAN, IMG_STD)\n",
    "                    im2_plot = tensor_to_image(im2[i], IMG_MEAN, IMG_STD)\n",
    "                    flow_gt_plot = flow_to_image(flow_gt[i].permute(1,2,0).cpu().numpy())\n",
    "                    flow_pred_plot = flow_to_image(flow_pred[i].permute(1,2,0).cpu().numpy())\n",
    "                    # Put your images in a list\n",
    "                    images = [im1_plot, im2_plot, flow_gt_plot, flow_pred_plot]\n",
    "                    titles = [\"Image 1\", \"Image 2\", \"Flow GT\", \"Flow Pred\"]\n",
    "                    \n",
    "                    fig, axes = plt.subplots(1, 4, figsize=(16, 4))  # 1 row, 4 columns\n",
    "                    \n",
    "                    for ax, img, title in zip(axes, images, titles):\n",
    "                        ax.imshow(img)\n",
    "                        ax.set_title(title)\n",
    "                        ax.axis(\"off\")\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "\n",
    "        val_loss /= float(batch_idx+1)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Train Loss: {train_loss}, val loss NN: {val_loss}\")\n",
    "    \n",
    "    if SAVE_MODEL:\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        # Save model and params\n",
    "        json_params_epoch = json_params.copy()\n",
    "        json_params_epoch[\"epoch\"] = epoch\n",
    "        json_params_epoch[\"train_loss\"] = train_loss\n",
    "        json_params_epoch[\"val_loss\"] = val_loss\n",
    "        model_path = os.path.join(folder_path,f\"model_{epoch}.pth\")\n",
    "        json_path = os.path.join(folder_path,f\"params_{epoch}.json\")\n",
    "        torch.save(model_head.state_dict(), model_path)\n",
    "        with open(json_path, \"w\") as outfile:\n",
    "            json.dump(json_params_epoch, outfile)\n",
    "    \n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a153aa-c94c-415b-9da6-a7f10b2025d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
